# -*- coding: utf-8 -*-
"""
è®€å– data/all_features.csv è¨“ç·´äºŒåˆ†é¡æ¨¡å‹ï¼ˆç†è§£=1 / å›°æƒ‘=0ï¼‰
- åŒæ™‚ä¿å­˜å¤šç‰ˆæœ¬ï¼ˆæª”åå« model èˆ‡æ™‚é–“æˆ³ï¼Œä¸è¦†è“‹ï¼‰
- å¯é¸äº¤å‰é©—è­‰ (--cv K)
- è¼¸å‡ºï¼šmodels/<tag>_<model>_<ts>_scaler.joblib
        models/<tag>_<model>_<ts>_model.joblib
        models/<tag>_<model>_<ts>_feat_meta.json
        models/latest.jsonï¼ˆè¨˜éŒ„æœ€å¾Œä¸€æ¬¡è¨“ç·´çš„ä¸‰å€‹è·¯å¾‘ï¼Œæ–¹ä¾¿å³æ™‚æ¨è«–ç›´æ¥è®€ï¼‰
"""

import os, json, argparse, time
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import (
    accuracy_score, precision_recall_fscore_support,
    roc_auc_score, confusion_matrix, classification_report
)
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from joblib import dump

def parse_args():
    ap = argparse.ArgumentParser()
    ap.add_argument("--csv", type=str, default=os.path.join("data", "all_features.csv"),
                    help="è³‡æ–™CSVè·¯å¾‘ï¼ˆé è¨­ data/all_features.csvï¼‰")
    ap.add_argument("--model", type=str, default="logreg", choices=["logreg","rf"],
                    help="åˆ†é¡å™¨ï¼šlogregï¼ˆé‚è¼¯è¿´æ­¸ï¼‰æˆ– rfï¼ˆéš¨æ©Ÿæ£®æ—ï¼‰")
    ap.add_argument("--test_size", type=float, default=0.2, help="æ¸¬è©¦é›†æ¯”ä¾‹ï¼Œé è¨­ 0.2")
    ap.add_argument("--random_state", type=int, default=42, help="éš¨æ©Ÿç¨®å­")
    ap.add_argument("--tag", type=str, default="default", help="è‡ªè¨‚æ¨™ç±¤ï¼ˆæœƒå¯«é€²æª”åï¼‰")
    ap.add_argument("--cv", type=int, default=0, help="K æŠ˜äº¤å‰é©—è­‰ï¼ˆ0=é—œé–‰ï¼›ä¾‹å¦‚ 5 å•Ÿç”¨ 5-foldï¼‰")
    return ap.parse_args()

def load_dataset(csv_path: str):
    if not os.path.exists(csv_path):
        raise SystemExit(f"âŒ æ‰¾ä¸åˆ°è³‡æ–™æª”ï¼š{csv_path}")

    df = pd.read_csv(csv_path, encoding="utf-8")
    if "label" not in df.columns:
        raise SystemExit("âŒ CSV ç¼ºå°‘ label æ¬„ä½ã€‚è«‹ç¢ºèªç”±è’é›†ç¨‹å¼å¯«å‡ºçš„æ ¼å¼ã€‚")

    df = df.dropna(subset=["label"])
    feat_cols = [c for c in df.columns if c.startswith(("dx_","dy_","dz_"))]
    if "face_width" in df.columns:  feat_cols.insert(0, "face_width")
    if "face_height" in df.columns: feat_cols.insert(1, "face_height")

    if len(feat_cols) == 0:
        raise SystemExit("âŒ æ‰¾ä¸åˆ°ç‰¹å¾µæ¬„ä½ï¼ˆdx_*, dy_*, dz_*ï¼‰ã€‚")

    X = df[feat_cols].to_numpy(dtype=np.float32)
    y = df["label"].astype(int).to_numpy()

    X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)

    print(f"âœ… è³‡æ–™ï¼š{len(y)} ç­†ï¼Œç‰¹å¾µç¶­åº¦ {X.shape[1]}")
    uniq, cnt = np.unique(y, return_counts=True)
    print("é¡åˆ¥åˆ†ä½ˆï¼š", dict(zip(uniq.tolist(), cnt.tolist())))
    return X, y, feat_cols

def build_model(kind: str, rs: int):
    if kind == "logreg":
        return LogisticRegression(
            class_weight="balanced",
            solver="saga",
            max_iter=1000,
            n_jobs=-1,
            random_state=rs
        )
    else:
        return RandomForestClassifier(
            n_estimators=400,
            max_depth=None,
            class_weight="balanced_subsample",
            n_jobs=-1,
            random_state=rs
        )

def kfold_eval(X, y, feat_cols, kind: str, rs: int, k: int):
    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=rs)
    accs, f1s, aucs = [], [], []
    for fold, (tr, va) in enumerate(skf.split(X, y), 1):
        scaler = StandardScaler()
        Xtr = scaler.fit_transform(X[tr])
        Xva = scaler.transform(X[va])

        clf = build_model(kind, rs)
        clf.fit(Xtr, y[tr])

        y_pred = clf.predict(Xva)
        acc = accuracy_score(y[va], y_pred)
        prec, rec, f1, _ = precision_recall_fscore_support(y[va], y_pred, average="binary", zero_division=0)

        if hasattr(clf, "predict_proba"):
            y_prob = clf.predict_proba(Xva)[:, 1]
            auc = roc_auc_score(y[va], y_prob)
        else:
            auc = np.nan

        accs.append(acc); f1s.append(f1); aucs.append(auc)
        print(f"[CV fold {fold}] Acc={acc:.4f}  F1={f1:.4f}  AUC={auc:.4f}")

    print("\n[CV å¹³å‡]")
    print(f"Acc={np.mean(accs):.4f}Â±{np.std(accs):.4f}  "
          f"F1={np.mean(f1s):.4f}Â±{np.std(f1s):.4f}  "
          f"AUC={np.mean(aucs):.4f}Â±{np.std(aucs):.4f}")

def main():
    args = parse_args()
    os.makedirs("models", exist_ok=True)

    X, y, feat_cols = load_dataset(args.csv)

    if args.cv and args.cv >= 2:
        print(f"\nğŸ” é€²è¡Œ {args.cv}-fold äº¤å‰é©—è­‰â€¦")
        kfold_eval(X, y, feat_cols, args.model, args.random_state, args.cv)

    X_tr, X_te, y_tr, y_te = train_test_split(
        X, y, test_size=args.test_size, random_state=args.random_state, stratify=y
    )

    scaler = StandardScaler()
    X_trs = scaler.fit_transform(X_tr)
    X_tes = scaler.transform(X_te)

    clf = build_model(args.model, args.random_state)
    clf.fit(X_trs, y_tr)

    y_pred = clf.predict(X_tes)
    auc = np.nan
    if hasattr(clf, "predict_proba"):
        y_prob = clf.predict_proba(X_tes)[:, 1]
        auc = roc_auc_score(y_te, y_prob)

    acc = accuracy_score(y_te, y_pred)
    prec, rec, f1, _ = precision_recall_fscore_support(y_te, y_pred, average="binary", zero_division=0)
    cm = confusion_matrix(y_te, y_pred)

    print("\n=== æ¸¬è©¦é›†è©•ä¼° ===")
    print(f"Accuracy : {acc:.4f}")
    print(f"Precision: {prec:.4f}")
    print(f"Recall   : {rec:.4f}")
    print(f"F1-score : {f1:.4f}")
    if not np.isnan(auc):
        print(f"ROC-AUC  : {auc:.4f}")
    print("\næ··æ·†çŸ©é™£ [[TN FP] [FN TP]]ï¼š")
    print(cm)
    print("\nåˆ†é¡å ±å‘Šï¼š")
    from sklearn.metrics import classification_report
    print(classification_report(y_te, y_pred, digits=4))

    # æª”åï¼š<tag>_<model>_<ts>_*.joblib/json
    ts = time.strftime("%Y%m%d_%H%M%S")
    stem = f"{args.tag}_{args.model}_{ts}"
    scaler_path = os.path.join("models", f"{stem}_scaler.joblib")
    model_path  = os.path.join("models", f"{stem}_model.joblib")
    meta_path   = os.path.join("models", f"{stem}_feat_meta.json")

    dump(scaler, scaler_path)
    dump(clf, model_path)
    with open(meta_path, "w", encoding="utf-8") as f:
        json.dump({"feature_names": feat_cols,
                   "model_type": args.model,
                   "n_features": len(feat_cols)}, f, ensure_ascii=False, indent=2)

    # å¯«ä¸€ä»½ latest.json æŒ‡å‘æœ€æ–°æ¨¡å‹ï¼ˆå³æ™‚æ¨è«–å¯ç›´æ¥è®€å®ƒï¼‰
    with open(os.path.join("models", "latest.json"), "w", encoding="utf-8") as f:
        json.dump({"scaler": scaler_path, "model": model_path, "meta": meta_path},
                  f, ensure_ascii=False, indent=2)

    print("\nâœ… å·²å„²å­˜ï¼š")
    print(" ", scaler_path)
    print(" ", model_path)
    print(" ", meta_path)
    print("â¡ models/latest.json ä¹Ÿå·²æ›´æ–°ï¼ˆæ–¹ä¾¿å³æ™‚æ¨è«–ç›´æ¥è®€å–ï¼‰")

if __name__ == "__main__":
    main()
